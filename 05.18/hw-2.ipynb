{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec5ad41",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "|        |         |                                @ |\n",
    "|:-------|:--------|---------------------------------:|\n",
    "| Luca   | Mosetti | luca.mosetti-1@studenti.unitn.it |\n",
    "| Shandy | Darma   |   shandy.darma@studenti.unitn.it |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Iterator, Callable, Iterable, SupportsFloat\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import doctest\n",
    "import math\n",
    "import matplotlib\n",
    "import heapq as hq\n",
    "import itertools as it\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import more_itertools as mit\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf589b1d",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "1. Repeat exercise 1 for an $\\text M/\\text M/c/K$ system where\n",
    "\n",
    "    - there are $c$ servers (start with $c = 2$, then test for larger values if time allows);\n",
    "    - the queue of each server can hold up to $K$ packets (start with some easy number such as $K = 10$): this means that a server having $K$ packets in queue would discard any other packets assigned to it.\n",
    "\n",
    "2. Experiment with simple packet assignment policies (round-robin, least-loaded servers first, ...) as well as with policies that consider the occupancy of the queue of the servers (e.g., avoid sending packets to servers that have a full queue, or to a queue that is more than $x\\%$ full, for some $x$).\n",
    "\n",
    "3. For each policy, plot a histogram showing the number of packets served by each of the $c$ servers, as well as the average distribution of the queuing delay experienced by each packet. You can show other metrics as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class START:\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class ARRIVAL:\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class DEPARTURE:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class ASSIGNED:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class SERVING:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class DISCARDED:\n",
    "    by: int\n",
    "\n",
    "\n",
    "ET = START | ARRIVAL | DEPARTURE\n",
    "LT = ASSIGNED | SERVING | DEPARTURE | DISCARDED\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class Event:\n",
    "    timestamp: float\n",
    "    event: ET\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class Log:\n",
    "    timestamp: float\n",
    "    log: LT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00d1fb",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "$$\n",
    "U \\sim \\text{Uniform}(0, 1) \\qquad X = - \\frac {\\log U} \\lambda \\sim \\text{Exp}(\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_to_exp(lmbd: float, u: float) -> float:\n",
    "    return -math.log(u) / lmbd\n",
    "\n",
    "\n",
    "def round_robin(last: int, servers: NDArray[np.uint]) -> int:\n",
    "    return (last + 1) % len(servers)\n",
    "\n",
    "\n",
    "def least_loaded(_: int, servers: NDArray[np.uint]) -> int:\n",
    "    return np.argmin(servers).item()\n",
    "\n",
    "\n",
    "def least_loaded_round_robin(last: int, servers: NDArray[np.uint]) -> int:\n",
    "    \"\"\"\n",
    "\n",
    "    >>> least_loaded_round_robin(1, [0, 0, 1, 0])\n",
    "    3\n",
    "\n",
    "    >>> least_loaded_round_robin(0, [0, 1, 1, 1])\n",
    "    0\n",
    "\n",
    "    >>> zs = np.zeros(10)\n",
    "    >>> all([ least_loaded_round_robin(last, zs) == round_robin(last, zs) for last in range(10) ])\n",
    "    True\n",
    "\n",
    "    >>> zs = np.zeros(10)\n",
    "    >>> all([ least_loaded_round_robin(last, zs) != least_loaded(last, zs) for last in range(9) ])\n",
    "    True\n",
    "    \"\"\"\n",
    "    shift: int = last + 1\n",
    "    return (np.argmin(np.roll(servers, -shift)).item() + shift) % len(servers)\n",
    "\n",
    "\n",
    "def mmck_simulation(\n",
    "        seed_arr: int,\n",
    "        seeds_dep: list[int],\n",
    "        lmbd: float,\n",
    "        mu: float,\n",
    "        k: int,\n",
    "        policy: Callable[[int, NDArray[np.uint]], int]\n",
    ") -> Iterator[Log]:\n",
    "    \"\"\"\n",
    "    Reproducible simulation of M/M/c/K queue-server system\n",
    "\n",
    "    >>> mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded)) == mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mmck_simulation(3, [7], 1, 1, 5, least_loaded)\n",
    "    >>> all(a.timestamp <= b.timestamp for a, b in mit.take(100, it.pairwise(l1m1c1k5)))\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k5) <= mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == SERVING(0) for l in l1m1c1k5) <= mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == DEPARTURE(0) for l in l1m1c1k5) <= mit.quantify(l.log == SERVING(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> l1m2c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 2, 5, least_loaded))\n",
    "    >>> l1m1_dep_over_arr = mit.quantify(l.log == DEPARTURE(0) for l in l1m1c1k5) / mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    >>> l1m2_dep_over_arr = mit.quantify(l.log == DEPARTURE(0) for l in l1m2c1k5) / mit.quantify(l.log == ASSIGNED(0) for l in l1m2c1k5)\n",
    "    >>> l1m1_dep_over_arr < l1m2_dep_over_arr\n",
    "    True\n",
    "\n",
    "   >>> l1m1c1k3 = mit.take(100, mmck_simulation(3, [7], 1, 1, 3, least_loaded))\n",
    "   >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "   >>> mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k3) > mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k5)\n",
    "   True\n",
    "\n",
    "   >>> lmc1 = mit.take(100, mmck_simulation(3, [7], 1e6, 1e-6, -1, least_loaded))\n",
    "   >>> mit.quantify(l.log == DISCARDED(0) for l in lmc1)\n",
    "   0\n",
    "   \"\"\"\n",
    "\n",
    "    c: int = len(seeds_dep)\n",
    "\n",
    "    assert c > 0\n",
    "\n",
    "    rng_arr: np.random.Generator = np.random.default_rng(seed_arr)\n",
    "\n",
    "    def next_arr(timestamp: float) -> Event:\n",
    "        return Event(\n",
    "            timestamp + uni_to_exp(lmbd, rng_arr.random()),\n",
    "            ARRIVAL()\n",
    "        )\n",
    "\n",
    "    rngs_dep: list[np.random.Generator] = [np.random.default_rng(seed_dep) for seed_dep in seeds_dep]\n",
    "\n",
    "    def next_dep(by: int, timestamp: float) -> Event:\n",
    "        return Event(\n",
    "            timestamp + uni_to_exp(mu, rngs_dep[by].random()),\n",
    "            DEPARTURE(by=by)\n",
    "        )\n",
    "\n",
    "    last: int = -1\n",
    "    servers: NDArray[np.uint] = np.zeros(c, np.uint)\n",
    "\n",
    "    timeline: list[Event] = [\n",
    "        Event(timestamp=0, event=START()),\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        e: Event = hq.heappop(timeline)\n",
    "        match e.event:\n",
    "\n",
    "            case START():\n",
    "                hq.heappush(timeline, next_arr(e.timestamp))\n",
    "\n",
    "            case ARRIVAL():\n",
    "                hq.heappush(timeline, next_arr(e.timestamp))\n",
    "\n",
    "                by: int = policy(last, servers.copy())\n",
    "                last = by\n",
    "                yield Log(e.timestamp, ASSIGNED(by=by))\n",
    "                match servers[by]:\n",
    "                    case 0:\n",
    "                        yield Log(e.timestamp, SERVING(by=by))\n",
    "                        servers[by] += 1\n",
    "                        hq.heappush(timeline, next_dep(by, e.timestamp))\n",
    "\n",
    "                    case x if x == k + 1:\n",
    "                        yield Log(e.timestamp, DISCARDED(by=by))\n",
    "\n",
    "                    case _:\n",
    "                        servers[by] += 1\n",
    "\n",
    "            case DEPARTURE(by):\n",
    "                yield Log(e.timestamp, DEPARTURE(by))\n",
    "\n",
    "                servers[by] -= 1\n",
    "                if servers[by] > 0:\n",
    "                    yield Log(e.timestamp, SERVING(by=by))\n",
    "                    hq.heappush(timeline, next_dep(by, e.timestamp))\n",
    "\n",
    "\n",
    "def waiting(c: int, xs: Iterator[Log], discarded: float | None = None) -> Iterable[tuple[float, int, float]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (arrival time, served by, waiting time)\n",
    "    For discarded packets (arrival time, served by, discarded)\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(20, ASSIGNED(0)), Log(30, ASSIGNED(0)), Log(40, SERVING(0))]\n",
    "    >>> logs_1 = [Log(15, ASSIGNED(1)), Log(18, SERVING(1)), Log(19, ASSIGNED(1)), Log(41, SERVING(1))]\n",
    "    >>> logs_2 = [Log(11, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(42, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(waiting(3, logs))\n",
    "    [(10, 0, 30), (11, 2, 19), (15, 1, 3), (19, 1, 22)]\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(20, ASSIGNED(0)), Log(30, ASSIGNED(0)), Log(40, SERVING(0))]\n",
    "    >>> logs_1 = [Log(15, ASSIGNED(1)), Log(18, SERVING(1)), Log(19, ASSIGNED(1)), Log(41, SERVING(1))]\n",
    "    >>> logs_2 = [Log(11, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(42, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(waiting(3, logs, 0))\n",
    "    [(10, 0, 30), (11, 2, 19), (15, 1, 3), (19, 1, 22), (31, 2, 0)]\n",
    "\n",
    "    >>> seeds_dep = [5, 7, 11, 13]\n",
    "    >>> simulation = mmck_simulation(3, seeds_dep, 1, 1, 3, round_robin)\n",
    "    >>> ws = mit.take(len(seeds_dep), waiting(len(seeds_dep), simulation))\n",
    "    >>> [ (server, awaited) for _, server, awaited in ws ]\n",
    "    [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def single_waiting(by: int, xs: Iterator[Log]) -> Iterator[tuple[float, int, float]]:\n",
    "        xs1, xs2 = it.tee(xs, 2)\n",
    "        las = (l.timestamp for l in xs1 if l.log == ASSIGNED(by))\n",
    "        lzs = ((l.log, l.timestamp) for l in xs2 if l.log in [DISCARDED(by), SERVING(by)])\n",
    "        match discarded:\n",
    "            case None:\n",
    "                return ((a, by, e - a) for a, (l, e) in zip(las, lzs) if l != DISCARDED(by))\n",
    "            case _:\n",
    "                return ((a, by, e - a if l != DISCARDED(by) else discarded) for a, (l, e) in zip(las, lzs))\n",
    "\n",
    "    xss: tuple[Iterator[Log], ...] = it.tee(xs, c)\n",
    "\n",
    "    ws: list[Iterator[tuple[float, int, float]]] = [single_waiting(by, xss[by]) for by in range(c)]\n",
    "\n",
    "    return hq.merge(*ws, key=lambda t: t[0])\n",
    "\n",
    "\n",
    "def timestamp_packets(c: int, xs: Iterator[Log]) -> Iterator[tuple[float, NDArray[...]]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (timestamp, [[packets served by 0, packets discarded by 0], ...])\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(15, ASSIGNED(0)), Log(15, DISCARDED(0)), Log(25, DEPARTURE(0))]\n",
    "    >>> logs_1 = [Log(11, ASSIGNED(1)), Log(20, DEPARTURE(1))]\n",
    "    >>> logs_2 = [Log(12, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(31, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(timestamp_packets(3, logs))\n",
    "    [(0, array([[0, 0],\n",
    "           [0, 0],\n",
    "           [0, 0]], dtype=uint64)), (10, array([[1, 0],\n",
    "           [0, 0],\n",
    "           [0, 0]], dtype=uint64)), (11, array([[1, 0],\n",
    "           [1, 0],\n",
    "           [0, 0]], dtype=uint64)), (12, array([[1, 0],\n",
    "           [1, 0],\n",
    "           [1, 0]], dtype=uint64)), (15, array([[1, 1],\n",
    "           [1, 0],\n",
    "           [1, 0]], dtype=uint64)), (20, array([[1, 0],\n",
    "           [0, 0],\n",
    "           [1, 0]], dtype=uint64)), (25, array([[0, 0],\n",
    "           [0, 0],\n",
    "           [1, 0]], dtype=uint64)), (31, array([[0, 0],\n",
    "           [0, 0],\n",
    "           [1, 1]], dtype=uint64))]\n",
    "    \"\"\"\n",
    "\n",
    "    def tracking(acc: tuple[float, NDArray[...]], timestamp_logs: tuple[float, list[Log]]) -> tuple[\n",
    "        float, NDArray[...]]:\n",
    "        pckts: NDArray[...] = acc[1].copy()\n",
    "        pckts[:, 1] = 0\n",
    "        timestamp, ls = timestamp_logs\n",
    "\n",
    "        for l in ls:\n",
    "            match l.log:\n",
    "                case ASSIGNED(by):\n",
    "                    pckts[by][0] += 1\n",
    "                case DEPARTURE(by):\n",
    "                    pckts[by][0] -= 1\n",
    "                case DISCARDED(by):\n",
    "                    pckts[by][0] -= 1\n",
    "                    pckts[by][1] += 1\n",
    "\n",
    "        return timestamp, pckts\n",
    "\n",
    "    same_timestamp: Iterator[tuple[float, list[Log]]] = it.groupby(\n",
    "        (l for l in xs if isinstance(l.log, ASSIGNED | DISCARDED | DEPARTURE)),\n",
    "        key=lambda l: l.timestamp\n",
    "    )\n",
    "\n",
    "    return it.accumulate(\n",
    "        same_timestamp,\n",
    "        tracking,\n",
    "        initial=(0, np.zeros((c, 2), dtype=np.uint))\n",
    "    )\n",
    "\n",
    "\n",
    "def timestamp_tot_packets(c: int, xs: Iterator[Log]) -> Iterator[tuple[float, NDArray[...]]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (timestamp, [[tot packets served by 0, tot packets discarded by 0], ...])\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(15, ASSIGNED(0)), Log(15, DISCARDED(0)), Log(25, DEPARTURE(0))]\n",
    "    >>> logs_1 = [Log(11, ASSIGNED(1)), Log(20, DEPARTURE(1))]\n",
    "    >>> logs_2 = [Log(12, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(31, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(timestamp_tot_packets(3, logs))\n",
    "    [(0, array([[0, 0],\n",
    "           [0, 0],\n",
    "           [0, 0]], dtype=uint64)), (10, array([[1, 0],\n",
    "           [0, 0],\n",
    "           [0, 0]], dtype=uint64)), (11, array([[1, 0],\n",
    "           [1, 0],\n",
    "           [0, 0]], dtype=uint64)), (12, array([[1, 0],\n",
    "           [1, 0],\n",
    "           [1, 0]], dtype=uint64)), (15, array([[1, 1],\n",
    "           [1, 0],\n",
    "           [1, 0]], dtype=uint64)), (31, array([[1, 1],\n",
    "           [1, 0],\n",
    "           [1, 1]], dtype=uint64))]\n",
    "    \"\"\"\n",
    "\n",
    "    def tracking(acc: tuple[float, NDArray[...]], timestamp_logs: tuple[float, list[Log]]) -> tuple[\n",
    "        float, NDArray[...]]:\n",
    "        pckts: NDArray[...] = acc[1].copy()\n",
    "        timestamp, ls = timestamp_logs\n",
    "\n",
    "        for l in ls:\n",
    "            match l.log:\n",
    "                case ASSIGNED(by):\n",
    "                    pckts[by][0] += 1\n",
    "                case DISCARDED(by):\n",
    "                    pckts[by][0] -= 1\n",
    "                    pckts[by][1] += 1\n",
    "\n",
    "        return timestamp, pckts\n",
    "\n",
    "    same_timestamp: Iterator[tuple[float, list[Log]]] = it.groupby(\n",
    "        (l for l in xs if isinstance(l.log, ASSIGNED | DISCARDED)),\n",
    "        key=lambda l: l.timestamp\n",
    "    )\n",
    "\n",
    "    return it.accumulate(\n",
    "        same_timestamp,\n",
    "        tracking,\n",
    "        initial=(0, np.zeros((c, 2), dtype=np.uint))\n",
    "    )\n",
    "\n",
    "\n",
    "def non_overlapping_batches(xs: Iterator[SupportsFloat | tuple[SupportsFloat, ...]], b: int, m: int) -> NDArray[...]:\n",
    "    \"\"\"\n",
    "    From sequence of tuple to non-overlapping batches NDArray\n",
    "\n",
    "    >>> non_overlapping_batches([(1.5, 1), (2.5, 2), (3.5, 3), (4.5, 4), (5.5, 5)], 2, 2)\n",
    "    array([[[1.5, 1. ],\n",
    "            [2.5, 2. ]],\n",
    "    <BLANKLINE>\n",
    "           [[3.5, 3. ],\n",
    "            [4.5, 4. ]]])\n",
    "    \"\"\"\n",
    "    vs: NDArray[...] = np.asarray(mit.take(m * b, xs))\n",
    "    return np.stack([vs[i * m:(i + 1) * m] for i in range(b)])\n",
    "\n",
    "\n",
    "def gamma() -> float:\n",
    "    return 0.95\n",
    "\n",
    "\n",
    "def populate(\n",
    "        a: plt.Axes,\n",
    "        b: int,\n",
    "        m: int,\n",
    "        mus: NDArray[float],\n",
    "        grand_mean: float,\n",
    "        seeds: tuple[int | list[int], ...],\n",
    "        lmbd: float,\n",
    "        mu: float,\n",
    "        k: int,\n",
    "        delta: float,\n",
    "        y_label: str,\n",
    "        policy: str,\n",
    "        color: int\n",
    ") -> None:\n",
    "    a.hlines(\n",
    "        y=mus,\n",
    "        xmin=np.arange(0, b) * m,\n",
    "        xmax=(np.arange(0, b) + 1) * m,\n",
    "        colors=[f'C{i}' for i in range(b)],\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    a.axhspan(\n",
    "        grand_mean - delta,\n",
    "        grand_mean + delta,\n",
    "        alpha=0.5,\n",
    "        color=f'C{color}',\n",
    "        label=f'CI {gamma()}'\n",
    "    )\n",
    "    a.axhline(\n",
    "        grand_mean,\n",
    "        label=r'$\\hat\\theta$',\n",
    "        color=f'C{color}',\n",
    "    )\n",
    "\n",
    "    a.legend(loc='upper left')\n",
    "    a.set_title(\n",
    "        f'${seeds} \\\\vdash \\\\lambda={lmbd}, \\\\mu={mu}, k={k}$ // non-overlapping $m = {m}, b = {b}$ // {policy}')\n",
    "    a.set_xlabel('samples')\n",
    "    a.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd5b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds: Iterator[int] = mit.sieve(1_000)\n",
    "mit.consume(seeds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4279ed2",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "For this simulation, we are going to implement 3 different policies:\n",
    "\n",
    "- Round Robin: This policy will fill the next queue incrementally. If it reaches the last queue, it will return to the first queue.\n",
    "- Least Loaded: This policy will find the queue with the least load. Assignment is not random, it will always start searching from the first queue.\n",
    "- Least Loaded Round Robin: This policy behaves like round robin, but instead it finds the next queue with least load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c: int = 2\n",
    "k: int = 10\n",
    "lmbd: float = 95 * c\n",
    "mu: float = 100\n",
    "\n",
    "policies: dict[str, Callable] = {\n",
    "    'round robin': round_robin,\n",
    "    'least loaded': least_loaded,\n",
    "    'least loaded round robin': least_loaded_round_robin,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_arr: int = next(seeds)\n",
    "seeds_dep: list[int] = mit.take(c, seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902dd756",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Waiting times\n",
    "\n",
    "First, we are going to measure the time it takes from a packet from the beginning of a queue to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a: plt.Axes\n",
    "f, axs = plt.subplots(len(policies), 1, figsize=(12, 5 * len(policies) + 2), sharex='all', sharey='all')\n",
    "\n",
    "for i, a, (name, policy) in zip(it.count(), axs, policies.items()):\n",
    "    ws: Iterable[tuple[float, int, float]] = waiting(\n",
    "        c,\n",
    "        mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy),\n",
    "        -0.025,\n",
    "    )\n",
    "\n",
    "    samples: list[tuple[float, int, float]] = mit.take(1_000, ws)\n",
    "\n",
    "    a.bar(\n",
    "        range(1, len(samples) + 1),\n",
    "        [w for _, _, w in samples],\n",
    "        color=[f'C{server}' for _, server, w in samples],\n",
    "        hatch=['\\\\' * 5 if w < 0 else '' for _, server, w in samples],\n",
    "    )\n",
    "\n",
    "    a.grid(True, axis='y')\n",
    "    a.set_axisbelow(True)\n",
    "    a.set_xlabel('packet')\n",
    "    a.set_ylabel('time')\n",
    "    a.set_title(f'$({seed_arr}, {seeds_dep}) \\\\vdash \\\\lambda={lmbd}, \\\\mu={mu}, k={k}$ // {name}')\n",
    "\n",
    "    if i == 0:\n",
    "        a.legend(\n",
    "            loc='upper left',\n",
    "            handles=[\n",
    "                        matplotlib.patches.Patch(\n",
    "                            color=f'C{server}',\n",
    "                            label=f'awaited in #{server + 1}'\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ] + [\n",
    "                        matplotlib.patches.Patch(\n",
    "                            edgecolor='black',\n",
    "                            facecolor=f'C{server}',\n",
    "                            hatch='\\\\' * 5,\n",
    "                            label=f'discarded by #{server + 1}',\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ],\n",
    "        )\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9162be7b",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Packets in the system over time\n",
    "\n",
    "In this section, we will see how many packets are in the system over time.\n",
    "The packets we measure are both in process and in queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a: plt.Axes\n",
    "f, axs = plt.subplots(len(policies), 1, figsize=(12, 5 * len(policies) + 2), sharex='all', sharey='all')\n",
    "\n",
    "for i, a, (name, policy) in zip(it.count(), axs, policies.items()):\n",
    "    timestamps_packets: Iterable[tuple[float, NDArray[...]]] = timestamp_packets(\n",
    "        c,\n",
    "        mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy)\n",
    "    )\n",
    "\n",
    "    samples: list[tuple[float, NDArray[...]]] = mit.take(500, timestamps_packets)\n",
    "    timestamps, pckts = zip(*samples)\n",
    "    timespans: NDArray[float] = np.asarray([t2 - t1 for t1, t2 in it.pairwise(it.chain([0], timestamps))], float)\n",
    "\n",
    "    xs: NDArray[int] = np.arange(len(pckts)) + 1\n",
    "    width: float = 0.5 / c\n",
    "\n",
    "    for server in range(c):\n",
    "        a.stairs(\n",
    "            [snapshot[server, 0] for snapshot in pckts],\n",
    "            edges=np.cumsum(np.append(0, timespans)),\n",
    "            color=f'C{server}',\n",
    "            alpha=0.5,\n",
    "            fill=True,\n",
    "        )\n",
    "        a.bar(\n",
    "            timestamps,\n",
    "            [snapshot[server, 1] * -1 for snapshot in pckts],\n",
    "            width=0.001,\n",
    "            facecolor='white',\n",
    "            edgecolor=f'C{server}',\n",
    "            alpha=0.5,\n",
    "            hatch='\\\\' * 5,\n",
    "        )\n",
    "\n",
    "    a.axhline(\n",
    "        0,\n",
    "        color='red',\n",
    "        linestyle='--'\n",
    "    )\n",
    "\n",
    "    a.axhline(\n",
    "        k + 1,\n",
    "        color='red',\n",
    "        linestyle='--'\n",
    "    )\n",
    "\n",
    "    a.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    a.set_xlabel('time')\n",
    "    a.set_ylabel('packets')\n",
    "    a.set_title(f'$({seed_arr}, {seeds_dep}) \\\\vdash \\\\lambda={lmbd}, \\\\mu={mu}, k={k}$ // {name}')\n",
    "\n",
    "    if i == 0:\n",
    "        a.legend(\n",
    "            loc='upper left',\n",
    "            handles=[\n",
    "                        matplotlib.patches.Patch(\n",
    "                            color=f'C{server}',\n",
    "                            alpha=0.5,\n",
    "                            label=f'packets served by #{server + 1}'\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ] + [\n",
    "                        matplotlib.patches.Patch(\n",
    "                            facecolor='white',\n",
    "                            edgecolor=f'C{server}',\n",
    "                            hatch='\\\\' * 5,\n",
    "                            alpha=0.5,\n",
    "                            label=f'packets discarded by #{server + 1}',\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ],\n",
    "        )\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db1f16",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Total packets\n",
    "\n",
    "In this section, we will see overall how many packets in total are processed by each server during the entire simulation runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs: list[plt.Axes]\n",
    "_, axs = plt.subplots(len(policies), 1, figsize=(12, 5 * len(policies) + 2), sharex='all', sharey='all')\n",
    "\n",
    "for i, a, (name, policy) in zip(it.count(), axs, policies.items()):\n",
    "    timestamps_packets: Iterable[tuple[float, NDArray[...]]] = timestamp_tot_packets(\n",
    "        c,\n",
    "        mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy)\n",
    "    )\n",
    "\n",
    "    samples: list[tuple[float, NDArray[...]]] = mit.take(100_000, timestamps_packets)\n",
    "    step: int = 1_000\n",
    "    _, pckts = zip(*samples)\n",
    "    pckts = np.asarray(pckts, int)[::step, :]\n",
    "\n",
    "    xs: NDArray[int] = np.arange(len(pckts)) + 1\n",
    "    width: float = 0.5 / c\n",
    "\n",
    "    for server in range(c):\n",
    "        a.bar(\n",
    "            xs + width * server,\n",
    "            pckts[:, server, 0],\n",
    "            width,\n",
    "            color=f'C{server}',\n",
    "            align='edge',\n",
    "        )\n",
    "        a.bar(\n",
    "            xs + width * server,\n",
    "            pckts[:, server, 1] * -1,\n",
    "            width,\n",
    "            color=f'C{server}',\n",
    "            align='edge',\n",
    "            hatch='\\\\' * 5,\n",
    "        )\n",
    "\n",
    "    a.axhline(\n",
    "        0,\n",
    "        color='red',\n",
    "        linestyle='--'\n",
    "    )\n",
    "\n",
    "    a.grid(True, axis='y')\n",
    "    a.set_axisbelow(True)\n",
    "    a.set_xticks(xs[::10], (xs[::10] * step).astype(str))\n",
    "    a.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    a.set_xlabel('arrivals')\n",
    "    a.set_ylabel('packets')\n",
    "    a.set_title(f'$({seed_arr}, {seeds_dep}) \\\\vdash \\\\lambda={lmbd}, \\\\mu={mu}, k={k}$ // {name}')\n",
    "\n",
    "    if i == 0:\n",
    "        a.legend(\n",
    "            loc='upper left',\n",
    "            handles=[\n",
    "                        matplotlib.patches.Patch(\n",
    "                            color=f'C{server}',\n",
    "                            label=f'tot packets served by #{server + 1}'\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ] + [\n",
    "                        matplotlib.patches.Patch(\n",
    "                            edgecolor='black',\n",
    "                            facecolor=f'C{server}',\n",
    "                            hatch='\\\\' * 5,\n",
    "                            label=f'tot packets discarded by #{server + 1}',\n",
    "                        )\n",
    "                        for server in range(c)\n",
    "                    ],\n",
    "        )\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy2pckts: dict[str, NDArray[...]] = {\n",
    "    name: pckts\n",
    "    for name, policy in policies.items()\n",
    "    for simulation in [mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy)]\n",
    "    for timestamps_packets in [timestamp_tot_packets(c, simulation)]\n",
    "    for _, pckts in [mit.nth(timestamps_packets, 100_000)]\n",
    "}\n",
    "\n",
    "f: plt.Figure\n",
    "axs: list[plt.Axes]\n",
    "f, axs = plt.subplots(1, len(policies), figsize=(12, 5), sharey='all')\n",
    "\n",
    "for i, a, (name, pckts) in zip(it.count(), axs, policy2pckts.items()):\n",
    "    bars = a.bar(\n",
    "        range(c),\n",
    "        pckts[:, 0],\n",
    "        color=[f'C{server}' for server in range(c)],\n",
    "        label=[f'tot packets served by #{server + 1}' for server in range(c)],\n",
    "    )\n",
    "    a.bar_label(bars)\n",
    "\n",
    "    bars = a.bar(\n",
    "        range(c),\n",
    "        pckts[:, 1],\n",
    "        color=[f'C{server}' for server in range(c)],\n",
    "        hatch='\\\\' * 5,\n",
    "        label=[f'tot packets discarded by #{server + 1}' for server in range(c)],\n",
    "    )\n",
    "    a.bar_label(bars)\n",
    "\n",
    "    a.yaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
    "    a.set_ylabel('packets')\n",
    "    a.set_title(name)\n",
    "\n",
    "    if i == 0:\n",
    "        a.legend(loc='center')\n",
    "\n",
    "f.suptitle(f'$({seed_arr}, {seeds_dep}) \\\\vdash \\\\lambda={lmbd}, \\\\mu={mu}, k={k}$')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb8877a",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "### Non-overlapping batches\n",
    "\n",
    "To better understand the behaviour of the policies, we will measure the mean of the waiting time.\n",
    "This will be done by simulating a long run, retrieving the metrics with non-overlapping batches to calculate a CI for the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b19652",
   "metadata": {},
   "outputs": [],
   "source": [
    "m: int = 1_000\n",
    "b: int = 200\n",
    "\n",
    "batchess: dict[str, NDArray[float]] = {\n",
    "    name: batches[:, :, 2]\n",
    "    for name, policy in policies.items()\n",
    "    for simulation in [mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy)]\n",
    "    for ws in [waiting(c, simulation)]\n",
    "    for batches in [non_overlapping_batches(ws, b, m)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34079e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "muss: dict[str, NDArray[float]] = {\n",
    "    name: np.average(batches, axis=1)\n",
    "    for name, batches in batchess.items()\n",
    "}\n",
    "muss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e05b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_means_v_delta: dict[str, NDArray[float]] = {\n",
    "    name: np.asarray([grand_mean, v, delta])\n",
    "    for name, mus in muss.items()\n",
    "    for grand_mean in [st.fmean(mus)]\n",
    "    for v in [np.sum((mus - grand_mean) ** 2) / (b - 1)]\n",
    "    for delta in [sp.stats.t.ppf((1 + gamma()) / 2, df=b - 1) * math.sqrt(v / b)]\n",
    "}\n",
    "grand_means_v_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34469dbd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "rows: int = len(policies) + 1\n",
    "\n",
    "axs: list[plt.Axes]\n",
    "_, axs = plt.subplots(rows, 1, figsize=(12, 5 * rows + 1), sharex='all', )  # sharey='all')\n",
    "\n",
    "for i, a, name in zip(it.count(), axs, policies.keys()):\n",
    "    mus = muss[name]\n",
    "    grand_mean, _, delta = grand_means_v_delta[name]\n",
    "    populate(a, b, m, mus, grand_mean, (seed_arr, seeds_dep), lmbd, mu, k, delta,\n",
    "             r'$\\mathbf{E}\\left[{\\rm awaited}\\right]$', name, i)\n",
    "\n",
    "    axs[-1].axhspan(\n",
    "        grand_mean - delta,\n",
    "        grand_mean + delta,\n",
    "        alpha=0.5,\n",
    "        color=f'C{i}',\n",
    "    )\n",
    "    axs[-1].axhline(\n",
    "        grand_mean,\n",
    "        color=f'C{i}',\n",
    "    )\n",
    "    axs[-1].set_ylabel(r'$\\mathbf{E}\\left[{\\rm awaited}\\right]$')\n",
    "    axs[-1].set_xlabel('samples')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcca2aa",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "Note: the metrics above are **not** comparable\n",
    "\n",
    "We need to take note that there in this simulation, the queue size is limited.\n",
    "A packet that was supposed to be assigned to a full queue will be discarded.\n",
    "A discarded packet will not be counted for waiting time.\n",
    "A policy which always discard would measure no waiting time.\n",
    "\n",
    "To make this comparison fair we repeat the simulation with no limitation on the queue size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c: int = 2\n",
    "k: int = -1\n",
    "lmbd: float = 95 * c\n",
    "mu: float = 100\n",
    "\n",
    "policies: dict[str, Callable] = {\n",
    "    'round robin': round_robin,\n",
    "    'least loaded': least_loaded,\n",
    "    'least loaded round robin': least_loaded_round_robin,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ae58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m: int = 1_000\n",
    "b: int = 200\n",
    "\n",
    "batchess: dict[str, NDArray[float]] = {\n",
    "    name: batches[:, :, 2]\n",
    "    for name, policy in policies.items()\n",
    "    for simulation in [mmck_simulation(seed_arr, seeds_dep, lmbd, mu, k, policy)]\n",
    "    for ws in [waiting(c, simulation)]\n",
    "    for batches in [non_overlapping_batches(ws, b, m)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "muss: dict[str, NDArray[float]] = {\n",
    "    name: np.average(batches, axis=1)\n",
    "    for name, batches in batchess.items()\n",
    "}\n",
    "muss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_means_v_delta: dict[str, NDArray[float]] = {\n",
    "    name: np.asarray([grand_mean, v, delta])\n",
    "    for name, mus in muss.items()\n",
    "    for grand_mean in [st.fmean(mus)]\n",
    "    for v in [np.sum((mus - grand_mean) ** 2) / (b - 1)]\n",
    "    for delta in [sp.stats.t.ppf((1 + gamma()) / 2, df=b - 1) * math.sqrt(v / b)]\n",
    "}\n",
    "grand_means_v_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d80651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows: int = len(policies) + 1\n",
    "\n",
    "axs: list[plt.Axes]\n",
    "_, axs = plt.subplots(rows, 1, figsize=(12, 5 * rows + 1), sharex='all', )  # sharey='all')\n",
    "\n",
    "for i, a, name in zip(it.count(), axs, policies.keys()):\n",
    "    mus = muss[name]\n",
    "    grand_mean, _, delta = grand_means_v_delta[name]\n",
    "    populate(a, b, m, mus, grand_mean, (seed_arr, seeds_dep), lmbd, mu, k, delta,\n",
    "             r'$\\mathbf{E}\\left[{\\rm awaited}\\right]$', name, i)\n",
    "\n",
    "    axs[-1].axhspan(\n",
    "        grand_mean - delta,\n",
    "        grand_mean + delta,\n",
    "        alpha=0.5,\n",
    "        color=f'C{i}',\n",
    "    )\n",
    "    axs[-1].axhline(\n",
    "        grand_mean,\n",
    "        color=f'C{i}',\n",
    "    )\n",
    "    axs[-1].set_ylabel(r'$\\mathbf{E}\\left[{\\rm awaited}\\right]$')\n",
    "    axs[-1].set_xlabel('samples')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd472494",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We can see from the plot above that the expected waiting time for round robin policy is higher than other policies.\n",
    "We should be able to infer that round robin policy performs worse compared to other, but we would like to calculate additional measurement to ensure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e373ee6b",
   "metadata": {
    "cell_marker": "r\"\"\""
   },
   "source": [
    "$$\n",
    "\\left[ \\overline Z_{1} - \\overline Z_{2} \\pm t_{2 (n - 1), \\frac {1 + \\gamma} 2} \\sqrt{\\frac{V_1 + V_2}{b}} \\right]_\\gamma\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cb07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1, p2 in it.combinations(policies.keys(), 2):\n",
    "    grand_mean1, v1, _ = grand_means_v_delta[p1]\n",
    "    grand_mean2, v2, _ = grand_means_v_delta[p2]\n",
    "\n",
    "    estimation = grand_mean1 - grand_mean2\n",
    "    delta = sp.stats.t.ppf((1 + gamma()) / 2, df=b * m * 2 - 2) * math.sqrt((v1 + v2) / b)\n",
    "\n",
    "    print(p1 + \" vs \" + p2)\n",
    "    print(estimation)\n",
    "    print(delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd25843",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "We can see that for both round robin against least loaded and round robin against least loaded round robin, the CIs are greater than zero, this means that round robin performs worse against the other policies.\n",
    "\n",
    "On the other hand, for least loaded against least loaded round robin, zero lies within the range of both CIs.\n",
    "This means that we cannot conclusively decide if one is better than the other."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
