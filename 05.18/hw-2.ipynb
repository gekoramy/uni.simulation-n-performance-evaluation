{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|        |         |                                @ |\n",
    "|:-------|:--------|---------------------------------:|\n",
    "| Luca   | Mosetti | luca.mosetti-1@studenti.unitn.it |\n",
    "| Shandy | Darma   |   shandy.darma@studenti.unitn.it |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Iterator, Callable, Iterable\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "import doctest\n",
    "import math\n",
    "import heapq as hq\n",
    "import itertools as it\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "import more_itertools as mit\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "1. Repeat exercise 1 for an $\\text M/\\text M/c/K$ system where\n",
    "\n",
    "    - there are $c$ servers (start with $c = 2$, then test for larger values if time allows);\n",
    "    - the queue of each server can hold up to $K$ packets (start with some easy number such as $K = 10$): this means that a server having $K$ packets in queue would discard any other packets assigned to it.\n",
    "\n",
    "2. Experiment with simple packet assignment policies (round-robin, least-loaded servers first, ...) as well as with policies that consider the occupancy of the queue of the servers (e.g., avoid sending packets to servers that have a full queue, or to a queue that is more than $x\\%$ full, for some $x$).\n",
    "\n",
    "3. For each policy, plot a histogram showing the number of packets served by each of the $c$ servers, as well as the average distribution of the queuing delay experienced by each packet. You can show other metrics as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class START:\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class ARRIVAL:\n",
    "    pass\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class DEPARTURE:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class ASSIGNED:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class SERVING:\n",
    "    by: int\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class DISCARDED:\n",
    "    by: int\n",
    "\n",
    "\n",
    "ET = START | ARRIVAL | DEPARTURE\n",
    "LT = ASSIGNED | SERVING | DEPARTURE | DISCARDED\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class Event:\n",
    "    timestamp: float\n",
    "    event: ET\n",
    "\n",
    "\n",
    "@dataclass(order=True, frozen=True, slots=True)\n",
    "class Log:\n",
    "    timestamp: float\n",
    "    log: LT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "U \\sim \\text{Uniform}(0, 1) \\qquad X = - \\frac {\\log U} \\lambda \\sim \\text{Exp}(\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni_to_exp(lmbd: float, u: float) -> float:\n",
    "    return -math.log(u) / lmbd\n",
    "\n",
    "\n",
    "def round_robin(last: int, servers: NDArray[np.uint]) -> int:\n",
    "    return (last + 1) % len(servers)\n",
    "\n",
    "\n",
    "def least_loaded(_: int, servers: NDArray[np.uint]) -> int:\n",
    "    return np.argmin(servers).item()\n",
    "\n",
    "\n",
    "def least_loaded_round_robin(last: int, servers: NDArray[np.uint]) -> int:\n",
    "    \"\"\"\n",
    "\n",
    "    >>> least_loaded_round_robin(1, [0, 0, 1, 0])\n",
    "    3\n",
    "\n",
    "    >>> least_loaded_round_robin(0, [0, 1, 1, 1])\n",
    "    0\n",
    "\n",
    "    >>> zs = np.zeros(10)\n",
    "    >>> all([ least_loaded_round_robin(a, zs) == round_robin(a, zs) for a in range(10) ])\n",
    "    True\n",
    "\n",
    "    >>> zs = np.zeros(10)\n",
    "    >>> all([ least_loaded_round_robin(a, zs) != least_loaded(a, zs) for a in range(9) ])\n",
    "    True\n",
    "    \"\"\"\n",
    "    shift: int = last + 1\n",
    "    return (np.argmin(np.roll(servers, -shift)).item() + shift) % len(servers)\n",
    "\n",
    "\n",
    "def mmck_simulation(\n",
    "        seed_arr: int,\n",
    "        seeds_dep: list[int],\n",
    "        lmbd: float,\n",
    "        mu: float,\n",
    "        k: int,\n",
    "        policy: Callable[[int, NDArray[np.uint]], int]\n",
    ") -> Iterator[Log]:\n",
    "    \"\"\"\n",
    "    Reproducible simulation of M/M/c/K queue-server system\n",
    "\n",
    "    >>> mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded)) == mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mmck_simulation(3, [7], 1, 1, 5, least_loaded)\n",
    "    >>> all(a.timestamp <= b.timestamp for a, b in mit.take(100, it.pairwise(l1m1c1k5)))\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k5) <= mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == SERVING(0) for l in l1m1c1k5) <= mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> mit.quantify(l.log == DEPARTURE(0) for l in l1m1c1k5) <= mit.quantify(l.log == SERVING(0) for l in l1m1c1k5)\n",
    "    True\n",
    "\n",
    "    >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "    >>> l1m2c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 2, 5, least_loaded))\n",
    "    >>> l1m1_dep_over_arr = mit.quantify(l.log == DEPARTURE(0) for l in l1m1c1k5) / mit.quantify(l.log == ASSIGNED(0) for l in l1m1c1k5)\n",
    "    >>> l1m2_dep_over_arr = mit.quantify(l.log == DEPARTURE(0) for l in l1m2c1k5) / mit.quantify(l.log == ASSIGNED(0) for l in l1m2c1k5)\n",
    "    >>> l1m1_dep_over_arr < l1m2_dep_over_arr\n",
    "    True\n",
    "\n",
    "   >>> l1m1c1k3 = mit.take(100, mmck_simulation(3, [7], 1, 1, 3, least_loaded))\n",
    "   >>> l1m1c1k5 = mit.take(100, mmck_simulation(3, [7], 1, 1, 5, least_loaded))\n",
    "   >>> mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k3) > mit.quantify(l.log == DISCARDED(0) for l in l1m1c1k5)\n",
    "   True\n",
    "   \"\"\"\n",
    "\n",
    "    c: int = len(seeds_dep)\n",
    "\n",
    "    assert c > 0\n",
    "    assert k > 0\n",
    "\n",
    "    rng_arr: np.random.Generator = np.random.default_rng(seed_arr)\n",
    "\n",
    "    def next_arr(timestamp: float) -> Event:\n",
    "        return Event(\n",
    "            timestamp + uni_to_exp(lmbd, rng_arr.random()),\n",
    "            ARRIVAL()\n",
    "        )\n",
    "\n",
    "    rngs_dep: list[np.random.Generator] = [np.random.default_rng(seed_dep) for seed_dep in seeds_dep]\n",
    "\n",
    "    def next_dep(by: int, timestamp: float) -> Event:\n",
    "        return Event(\n",
    "            timestamp + uni_to_exp(mu, rngs_dep[by].random()),\n",
    "            DEPARTURE(by=by)\n",
    "        )\n",
    "\n",
    "    last: int = -1\n",
    "    servers: NDArray[np.uint] = np.zeros(c, np.uint)\n",
    "\n",
    "    timeline: list[Event] = [\n",
    "        Event(timestamp=0, event=START()),\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        e: Event = hq.heappop(timeline)\n",
    "        match e.event:\n",
    "\n",
    "            case START():\n",
    "                hq.heappush(timeline, next_arr(e.timestamp))\n",
    "\n",
    "            case ARRIVAL():\n",
    "                hq.heappush(timeline, next_arr(e.timestamp))\n",
    "\n",
    "                by: int = policy(last, servers.copy())\n",
    "                last = by\n",
    "                yield Log(e.timestamp, ASSIGNED(by=by))\n",
    "                match servers[by]:\n",
    "                    case 0:\n",
    "                        yield Log(e.timestamp, SERVING(by=by))\n",
    "                        servers[by] += 1\n",
    "                        hq.heappush(timeline, next_dep(by, e.timestamp))\n",
    "\n",
    "                    case x if x == k + 1:\n",
    "                        yield Log(e.timestamp, DISCARDED(by=by))\n",
    "\n",
    "                    case _:\n",
    "                        servers[by] += 1\n",
    "\n",
    "            case DEPARTURE(by):\n",
    "                yield Log(e.timestamp, DEPARTURE(by))\n",
    "\n",
    "                servers[by] -= 1\n",
    "                if servers[by] > 0:\n",
    "                    yield Log(e.timestamp, SERVING(by=by))\n",
    "                    hq.heappush(timeline, next_dep(by, e.timestamp))\n",
    "\n",
    "\n",
    "def waiting(c: int, xs: Iterator[Log]) -> Iterable[tuple[float, int, float]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (arrival time, served by, waiting time)\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(20, ASSIGNED(0)), Log(30, ASSIGNED(0)), Log(40, SERVING(0))]\n",
    "    >>> logs_1 = [Log(15, ASSIGNED(1)), Log(18, SERVING(1)), Log(19, ASSIGNED(1)), Log(41, SERVING(1))]\n",
    "    >>> logs_2 = [Log(11, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(42, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(waiting(3, logs))\n",
    "    [(10, 0, 30), (11, 2, 19), (15, 1, 3), (19, 1, 22)]\n",
    "    \"\"\"\n",
    "\n",
    "    def single_waiting(by: int, xs: Iterator[Log]) -> Iterator[tuple[float, int, float]]:\n",
    "        xs1, xs2 = it.tee(xs, 2)\n",
    "        las = (l.timestamp for l in xs1 if l.log == ASSIGNED(by))\n",
    "        lzs = ((l.log, l.timestamp) for l in xs2 if l.log in [DISCARDED(by), SERVING(by)])\n",
    "        return ((a, by, e - a) for a, (l, e) in zip(las, lzs) if l != DISCARDED(by))\n",
    "\n",
    "    xss: tuple[Iterator[Log], ...] = it.tee(xs, c)\n",
    "\n",
    "    ws: list[Iterator[tuple[float, int, float]]] = [single_waiting(by, xss[by]) for by in range(c)]\n",
    "\n",
    "    return hq.merge(*ws, key=lambda t: t[0])\n",
    "\n",
    "\n",
    "def timestamp_packets(c: int, xs: Iterator[Log]) -> Iterator[tuple[float, NDArray[np.uint]]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (time, (packets served by 0, ...))\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(15, ASSIGNED(0)), Log(15, DISCARDED(0)), Log(25, DEPARTURE(0))]\n",
    "    >>> logs_1 = [Log(11, ASSIGNED(1)), Log(20, DEPARTURE(1))]\n",
    "    >>> logs_2 = [Log(12, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(42, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(timestamp_packets(3, logs))\n",
    "    [(0, array([0, 0, 0], dtype=uint64)), (10, array([1, 0, 0], dtype=uint64)), (11, array([1, 1, 0], dtype=uint64)), (12, array([1, 1, 1], dtype=uint64)), (15, array([2, 1, 1], dtype=uint64)), (15, array([1, 1, 1], dtype=uint64)), (20, array([1, 0, 1], dtype=uint64)), (25, array([0, 0, 1], dtype=uint64)), (31, array([0, 0, 2], dtype=uint64)), (42, array([0, 0, 1], dtype=uint64))]\n",
    "    \"\"\"\n",
    "\n",
    "    def timestamp_packets(acc: tuple[float, NDArray[np.uint]], l: Log) -> tuple[float, NDArray[np.uint]]:\n",
    "        pckts = acc[1].copy()\n",
    "        match l.log:\n",
    "            case ASSIGNED(by):\n",
    "                pckts[by] += 1\n",
    "                return l.timestamp, pckts\n",
    "            case DISCARDED(by) | DEPARTURE(by):\n",
    "                pckts[by] -= 1\n",
    "                return l.timestamp, pckts\n",
    "\n",
    "    return it.accumulate(\n",
    "        (l for l in xs if isinstance(l.log, ASSIGNED | DISCARDED | DEPARTURE)),\n",
    "        timestamp_packets,\n",
    "        initial=(0, np.zeros(c, dtype=np.uint))\n",
    "    )\n",
    "\n",
    "\n",
    "def timestamp_tot_packets(c: int, xs: Iterator[Log]) -> Iterator[tuple[float, NDArray[np.uint]]]:\n",
    "    \"\"\"\n",
    "    From sequence of logs to sequence of (time, (tot packets served by 0, ...))\n",
    "\n",
    "    >>> logs_0 = [Log(10, ASSIGNED(0)), Log(15, ASSIGNED(0)), Log(15, DISCARDED(0)), Log(25, DEPARTURE(0))]\n",
    "    >>> logs_1 = [Log(11, ASSIGNED(1)), Log(20, DEPARTURE(1))]\n",
    "    >>> logs_2 = [Log(12, ASSIGNED(2)), Log(30, SERVING(2)), Log(31, ASSIGNED(2)), Log(42, DISCARDED(2))]\n",
    "    >>> logs = sorted(it.chain(logs_0, logs_1, logs_2), key=lambda l: l.timestamp)\n",
    "    >>> list(timestamp_tot_packets(3, logs))\n",
    "    [(0, array([0, 0, 0], dtype=uint64)), (10, array([1, 0, 0], dtype=uint64)), (11, array([1, 1, 0], dtype=uint64)), (12, array([1, 1, 1], dtype=uint64)), (15, array([2, 1, 1], dtype=uint64)), (15, array([1, 1, 1], dtype=uint64)), (31, array([1, 1, 2], dtype=uint64)), (42, array([1, 1, 1], dtype=uint64))]\n",
    "    \"\"\"\n",
    "\n",
    "    def timestamp_tot_packets(acc: tuple[float, NDArray[np.uint]], l: Log) -> tuple[float, NDArray[np.uint]]:\n",
    "        pckts = acc[1].copy()\n",
    "        match l.log:\n",
    "            case ASSIGNED(by):\n",
    "                pckts[by] += 1\n",
    "                return l.timestamp, pckts\n",
    "            case DISCARDED(by):\n",
    "                pckts[by] -= 1\n",
    "                return l.timestamp, pckts\n",
    "\n",
    "    return it.accumulate(\n",
    "        (l for l in xs if isinstance(l.log, ASSIGNED | DISCARDED)),\n",
    "        timestamp_tot_packets,\n",
    "        initial=(0, np.zeros(c, dtype=np.uint))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctest.testmod()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
